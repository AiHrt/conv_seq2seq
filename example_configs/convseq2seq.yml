model: ConvSeq2Seq
model_params:
  attention.class: seq2seq.decoders.attention.AttentionLayerDot
  attention.params:
    num_units: 128
  bridge.class: seq2seq.models.bridges.ZeroBridge
  embedding.dim: 128
  encoder.class: seq2seq.encoders.ConvEncoderFairseq
  encoder.params:
    cnn.layers: 4
    cnn.nhids: 512,512,512,512
    cnn.kwidths: 3,3,3,3
  decoder.class: seq2seq.decoders.ConvDecoder
  decoder.params:
    cnn.layers: 3
    cnn.nhids: 512,512,512
    cnn.kwidths: 3,3,3
  optimizer.name: Adam
  optimizer.params:
    epsilon: 0.0000008
  optimizer.learning_rate: 0.0001
  source.max_seq_len: 50
  source.reverse: false
  target.max_seq_len: 50
